# Snowpark Pipelines

 To facilitate effective collaboration and streamline the development process, we utilized the Snowpark Python guide and the associated GitHub repository for data engineering with Snowpark. The implementation involves a minimum of three SQL processes and three User Defined Functions, leveraging two or all three datasets in the queries. Additionally, the project integrates Git actions for deployment purposes, following a continuous integration and continuous deployment (CI/CD) approach. A custom chatbot is being created using streamlit and deployed to GCP to assist users with table specific queries using natural language.

# Links

- LiveApp -  http://34.138.77.87:8501
- Codelabs - https://codelabs-preview.appspot.com/?file_id=13uqHijBfilRTQC1tcUzJakhdgnErHdQ7kWU1MLHrcMM#3

# Project Tree

```
ðŸ“¦ 
â”œâ”€ .DS_Store
â”œâ”€ .devcontainer
â”‚  â””â”€ config
â”œâ”€ .github
â”‚  â””â”€ workflows
â”‚     â””â”€ build_and_deploy.yaml
â”œâ”€ .gitignore
â”œâ”€ AskMe.py
â”œâ”€ Pipfile
â”œâ”€ Pipfile.lock
â”œâ”€ README.md
â”œâ”€ deploy_covid_pipelines.py
â”œâ”€ image.jpg
â”œâ”€ pages
â”‚  â””â”€ 1_ViewData.py
â”œâ”€ requirements.txt
â”œâ”€ snowflake
â”‚  â”œâ”€ .DS_Store
â”‚  â”œâ”€ 01_setup_snowflake.sql
â”‚  â”œâ”€ 02_load_coviddata.sql
â”‚  â”œâ”€ 05_create_view_one.py
â”‚  â”œâ”€ Data_transformation
â”‚  â”‚  â”œâ”€ covid_vaccinations
â”‚  â”‚  â”‚  â”œâ”€ 01_loading_covid_vaccinations.sql
â”‚  â”‚  â”‚  â””â”€ 02_transforming_covid_vaccinations.sql
â”‚  â”‚  â”œâ”€ retail_data
â”‚  â”‚  â”‚  â”œâ”€ 01_loading_retail_data.sql
â”‚  â”‚  â”‚  â””â”€ 02_transforming_retail_data.sql
â”‚  â”‚  â””â”€ who_situation_reports
â”‚  â”‚     â”œâ”€ 01_cleaning_who_situation_reports.sql
â”‚  â”‚     â””â”€ 02_transforming_who_situation_reports.sql
â”‚  â”œâ”€ Pipfile
â”‚  â”œâ”€ Pipfile.lock
â”‚  â”œâ”€ SQL_Processes
â”‚  â”‚  â”œâ”€ 01_test.sql
â”‚  â”‚  â”œâ”€ 02_test.sql
â”‚  â”‚  â”œâ”€ 03_test.sql
â”‚  â”‚  â””â”€ 04_test.sql
â”‚  â”œâ”€ User_Defined_Functions
â”‚  â”‚  â”œâ”€ Mortality
â”‚  â”‚  â”‚  â”œâ”€ .gitignore
â”‚  â”‚  â”‚  â”œâ”€ app.py
â”‚  â”‚  â”‚  â”œâ”€ app.sql
â”‚  â”‚  â”‚  â””â”€ app.toml
â”‚  â”‚  â”œâ”€ Normalized_Sales
â”‚  â”‚  â”‚  â”œâ”€ .gitignore
â”‚  â”‚  â”‚  â”œâ”€ app.py
â”‚  â”‚  â”‚  â”œâ”€ app.sql
â”‚  â”‚  â”‚  â””â”€ app.toml
â”‚  â”‚  â””â”€ Vaccinations
â”‚  â”‚     â”œâ”€ .gitignore
â”‚  â”‚     â”œâ”€ app.py
â”‚  â”‚     â”œâ”€ app.sql
â”‚  â”‚     â””â”€ app.toml
â”‚  â”œâ”€ requirements.txt
â”‚  â””â”€ teardown.sql
â””â”€ utils
   â”œâ”€ __init__.py
   â””â”€ snowpark_utils.py
```
# Environment Variables

```
#Openai
OPENAI_API="Your_Secret_Key"

# Snowflake 
SNOWFLAKE_ACCOUNT=""
SNOWFLAKE_USER=""
SNOWFLAKE_PASSWORD=""
SNOWFLAKE_ROLE=""
SNOWFLAKE_DATABASE="HOL_DB1"
SNOWFLAKE_TABLE1="COVID_WORLDWIDE"
SNOWFLAKE_TABLE2="COVID_VACCINES"
SNOWFLAKE_TABLE3="RETAIL_DATA"
```

# Create virtual environment for streamlit

### Install virtualenv if you haven't already
```
pip install virtualenv
```

### Create a virtual environment
```
virtualenv myenv
```

### Create python environment for the directory
```
python -m venv myenv
```

### Activate the virtual environment
```
source myenv/bin/activate
```

### Pip install requirements
```
pip install -r requirements.txt
```

# Streamlit Installation & Activation

```
$ mkdir streamlit

$ cd streamlit 

$ mkdir .streamlit

$ python -m venv .streamlit 

$ source .streamlit/bin/activate

$ cd ..
```

### Run streamlit application
```
streamlit run AskMe.py
```

# Forked Repositories - Snowpark

Manohar - https://github.com/Manuindukuri/snowflake_fork

Prathamesh - https://github.com/PrathamHusky07/Snowpark_Pipelines

Sarvesh - https://github.com/sarvesh3737/sfguide-data-engineering-with-snowpark-python

### Team Information and Contribution 

Name | NUID | Contribution 
--- | --- | --- |
Manohar Indukuri | 002774942 | 34% 
Prathamesh Kulkarni | 001560684 | 33% 
Sarvesh Malpani | 002776061 | 33% 

# ATTESTATION:

WE ATTEST THAT WE HAVENâ€™T USED ANY OTHER STUDENTSâ€™ WORK IN OUR ASSIGNMENT AND ABIDE BY THE POLICIES LISTED IN THE STUDENT HANDBOOK.
